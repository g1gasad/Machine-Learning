{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71076b7c-8b9b-4fda-a8b6-1274d12d378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28677586-0955-43ca-86c2-f22be7fa87fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_mae(max_depth, train_X, val_X, train_y, val_y):\n",
    "    model = RandomForestRegressor(n_estimators=100, max_depth=max_depth, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    predictions = model.predict(val_X)\n",
    "    mae = mean_absolute_error(predictions, val_y)\n",
    "    return mae\n",
    "    \n",
    "def gbm_rmse(train_X, val_X, train_y, val_y):\n",
    "    model = GradientBoostingRegressor(n_estimators=100, random_state=1)\n",
    "    model.fit(train_X, train_y)\n",
    "    predictions = model.predict(val_X)\n",
    "    rmse = np.sqrt(mean_squared_error(predictions, val_y))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f33db0db-0804-433f-a8c8-cfba4194aec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities LotConfig  ... PoolArea PoolQC Fence MiscFeature  \\\n",
       "0         Lvl    AllPub    Inside  ...        0    NaN   NaN         NaN   \n",
       "1         Lvl    AllPub       FR2  ...        0    NaN   NaN         NaN   \n",
       "2         Lvl    AllPub    Inside  ...        0    NaN   NaN         NaN   \n",
       "3         Lvl    AllPub    Corner  ...        0    NaN   NaN         NaN   \n",
       "4         Lvl    AllPub       FR2  ...        0    NaN   NaN         NaN   \n",
       "\n",
       "  MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0       0      2    2008        WD         Normal     208500  \n",
       "1       0      5    2007        WD         Normal     181500  \n",
       "2       0      9    2008        WD         Normal     223500  \n",
       "3       0      2    2006        WD        Abnorml     140000  \n",
       "4       0     12    2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"E:/Projects/Learning/ML/Housing Prices Prediction/Data/train.csv\").drop(\"Id\", axis=1)\n",
    "test_df = pd.read_csv(\"E:/Projects/Learning/ML/Housing Prices Prediction/Data/test.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5108cf1c-4630-4fa9-800f-79a4e96bf721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "234de8be-c291-4718-a255-df5f8e5383d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1460, 63) | NaN Values: 348\n",
      "Shape of X_test: (1459, 63) | NaN Values: 330\n",
      "Both DataFrames have same Columns\n"
     ]
    }
   ],
   "source": [
    "X = train_df.dropna(axis=0, subset='SalePrice')\n",
    "X = X.drop('SalePrice', axis=1)\n",
    "X_test = test_df.drop(\"Id\", axis=1)\n",
    "y = train_df.SalePrice\n",
    "\n",
    "missing_value_ocol_train = [col for col in X.columns if X[col].isna().any() and X[col].dtype == 'object']\n",
    "X = X.drop(missing_value_ocol_train, axis=1)\n",
    "object_cols = [col for col in X.columns if X[col].dtype == 'object']\n",
    "X_test = X_test.drop(missing_value_ocol_train, axis=1)\n",
    "\n",
    "# There are more columns in test data with missing values\n",
    "missing_value_ocol_test = [col for col in X_test.columns if X_test[col].isna().any() and X_test[col].dtype == 'object']\n",
    "# Filling NaN values because dropping isn't an option\n",
    "for col in missing_value_ocol_test:\n",
    "    if X_test[col].dtype == 'object':\n",
    "        most_frequent_value = X_test[col].mode()[0]\n",
    "        X_test[col].fillna(most_frequent_value, inplace=True)\n",
    "\n",
    "# X_test must have 1459 rows\n",
    "print(\"Shape of X:\", X.shape, \"| NaN Values:\", X.isna().sum().sum())\n",
    "print(\"Shape of X_test:\", X_test.shape, \"| NaN Values:\", X_test.isna().sum().sum())\n",
    "# Checking if both have same Columns\n",
    "if list(X_test.columns) == list(X.columns):\n",
    "    print(\"Both DataFrames have same Columns\")\n",
    "else:\n",
    "    print(\"There's a difference in columns between the DataFrames\")\n",
    "    \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab784ce3-ecc8-4b19-8492-48bd3ec6b25e",
   "metadata": {},
   "source": [
    "## Imputing Numerical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffa1d2e4-8e2b-40b5-a473-c9a9e91e7f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_X_train = X_train.select_dtypes(exclude='object')\n",
    "num_X_valid = X_valid.select_dtypes(exclude='object')\n",
    "num_X_test = X_test.select_dtypes(exclude='object')\n",
    "\n",
    "my_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(num_X_train))\n",
    "imputed_X_valid = pd.DataFrame(my_imputer.transform(num_X_valid))\n",
    "imputed_X_test = pd.DataFrame(my_imputer.transform(num_X_test))\n",
    "\n",
    "imputed_X_train.columns = num_X_train.columns\n",
    "imputed_X_valid.columns = num_X_valid.columns\n",
    "imputed_X_test.columns = num_X_test.columns\n",
    "\n",
    "imputed_X_train.index = num_X_train.index\n",
    "imputed_X_valid.index = num_X_valid.index\n",
    "imputed_X_test.index = num_X_test.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7c90d3-3581-441e-b0c0-27a8f5fe26ec",
   "metadata": {},
   "source": [
    "## Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ea377e0-2bbe-4689-861b-d79d65e05613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with good labels that are gonna be ordinally encoded:\n",
      " ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'BldgType', 'HouseStyle', 'RoofStyle', 'Exterior1st', 'Exterior2nd', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
      "\n",
      "Columns with bad labels that'll be dropped: ['RoofMatl', 'Condition2', 'Functional']\n"
     ]
    }
   ],
   "source": [
    "good_label_cols = [col for col in object_cols if set(X_valid[col]).issubset(X_train[col])]\n",
    "bad_label_cols = list(set(object_cols) - set(good_label_cols))\n",
    "\n",
    "print(\"Columns with good labels that are gonna be ordinally encoded:\\n\", good_label_cols)\n",
    "print()\n",
    "print(\"Columns with bad labels that'll be dropped:\", bad_label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "287c9a98-a1aa-4ef2-a455-5ea98511e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "object_X_train = X_train[good_label_cols].copy()\n",
    "object_X_valid = X_valid[good_label_cols].copy()\n",
    "object_X_test = X_test[good_label_cols].copy()\n",
    "\n",
    "ord_X_train = pd.DataFrame(ordinal_encoder.fit_transform(object_X_train))\n",
    "ord_X_valid = pd.DataFrame(ordinal_encoder.transform(object_X_valid))\n",
    "ord_X_test = pd.DataFrame(ordinal_encoder.transform(object_X_test))\n",
    "\n",
    "ord_X_train.index = object_X_train.index\n",
    "ord_X_valid.index = object_X_valid.index\n",
    "ord_X_test.index = object_X_test.index\n",
    "\n",
    "col_names_to_replace_with = {col: \"col_\"+str(col+1) for col in ord_X_train.columns}\n",
    "ord_X_train = ord_X_train.rename(columns=col_names_to_replace_with)\n",
    "ord_X_valid = ord_X_valid.rename(columns=col_names_to_replace_with)\n",
    "ord_X_test = ord_X_test.rename(columns=col_names_to_replace_with)\n",
    "\n",
    "label_X_train = pd.concat([imputed_X_train, ord_X_train], axis=1)\n",
    "label_X_valid = pd.concat([imputed_X_valid, ord_X_valid], axis=1)\n",
    "label_X_test = pd.concat([imputed_X_test, ord_X_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "373659a1-cbc4-411f-ab44-258dc7dcc8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17296.766156112557, 30077.35838597809)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_mae(10, label_X_train, label_X_valid, y_train, y_valid), gbm_rmse(label_X_train, label_X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ef4376-8cb8-4e05-b4b7-d8a21ef1031a",
   "metadata": {},
   "source": [
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cde089a-219a-4709-af2e-26ab7c197e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {col: X_train[col].nunique() for col in object_cols}\n",
    "d_sorted = sorted(d.items(), key=lambda item:item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd2a3e60-e6ac-4f5e-b1f4-dff79b4438c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_cardinal_col = [col for col in object_cols if X_train[col].nunique() < 10]\n",
    "high_cardinal_col = list(set(object_cols) - set(low_cardinal_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a789772-edcc-4098-96d6-713805ee32e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "OH_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "low_cardinality_X_train = X_train[low_cardinal_col].copy()\n",
    "low_cardinality_X_valid = X_valid[low_cardinal_col].copy()\n",
    "low_cardinality_X_test = X_test[low_cardinal_col].copy()\n",
    "\n",
    "ohe_train = pd.DataFrame(OH_encoder.fit_transform(low_cardinality_X_train))\n",
    "ohe_valid = pd.DataFrame(OH_encoder.transform(low_cardinality_X_valid))\n",
    "ohe_test = pd.DataFrame(OH_encoder.transform(low_cardinality_X_test))\n",
    "\n",
    "ohe_train.index = low_cardinality_X_train.index\n",
    "ohe_valid.index = low_cardinality_X_valid.index\n",
    "ohe_test.index = low_cardinality_X_test.index\n",
    "\n",
    "OH_col_names_to_replace_with = {col: \"col_\"+str(col+1) for col in ohe_train.columns}\n",
    "ohe_train = ohe_train.rename(columns=OH_col_names_to_replace_with)\n",
    "ohe_valid = ohe_valid.rename(columns=OH_col_names_to_replace_with)\n",
    "ohe_test = ohe_test.rename(columns=OH_col_names_to_replace_with)\n",
    "\n",
    "OH_X_train = pd.concat([imputed_X_train, ohe_train], axis=1)\n",
    "OH_X_valid = pd.concat([imputed_X_valid, ohe_valid], axis=1)\n",
    "OH_X_test = pd.concat([imputed_X_test, ohe_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c94705bb-a5ee-4990-a6c1-1d0176b01dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17624.56109655572, 29251.68800032398)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_mae(10, OH_X_train, OH_X_valid, y_train, y_valid), gbm_rmse(OH_X_train, OH_X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b8bb86b-1dc9-4d9f-903d-e76af5b0a3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_pred_result(X_train, y_train, X_test):\n",
    "    # Prediction from RandomForest Model\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=1)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_preds = rf_model.predict(X_test)\n",
    "    # Prediction from GBM Model\n",
    "    gbm_model = GradientBoostingRegressor(n_estimators=100, random_state=1)\n",
    "    gbm_model.fit(X_train, y_train)\n",
    "    gbm_preds = gbm_model.predict(X_test)\n",
    "    # Averaging both Predictions\n",
    "    return (rf_preds + gbm_preds) / 2\n",
    "\n",
    "Label_final_preds = final_pred_result(label_X_train, y_train, label_X_test)\n",
    "OH_final_preds = final_pred_result(OH_X_train, y_train, OH_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d15c8fc1-6872-4f98-ba90-6c0b59bac768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As of now, my best score is from Label_final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d37ded26-1e09-4d8a-868a-b49a74c77b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': test_df['Id'], 'SalePrice': OH_final_preds})\n",
    "output.to_csv(\"Submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85bf0b49-2e79-485e-9755-d939fc7bb760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I haven't trained my model on full data yet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
